{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from functools import partial\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from matplotlib.colors import Normalize, LogNorm\n",
    "import pandas as pd\n",
    "import clemb\n",
    "from clemb.forward_model import Forwardmodel\n",
    "from clemb.syn_model import SynModel\n",
    "from clemb.uks import UnscentedKalmanSmoother\n",
    "\n",
    "from filterpy.kalman import UnscentedKalmanFilter as UKF\n",
    "from filterpy.common import Q_discrete_white_noise\n",
    "from filterpy.kalman import MerweScaledSigmaPoints, unscented_transform\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "import param\n",
    "import panel as pn\n",
    "\n",
    "import IPython.core.debugger\n",
    "dbg = IPython.core.debugger.Pdb()\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bqplot.scales import LinearScale, DateScale, LogScale\n",
    "from bqplot.interacts import PanZoom\n",
    "from bqplot.marks import *\n",
    "from bqplot.axes import Axis\n",
    "from bqplot.figure import Figure\n",
    "from bqplot.toolbar import Toolbar\n",
    "\n",
    "from ipywidgets import VBox, HBox\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from clemb.syn_model import SynModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds = SynModel(seed=42).run(1000., nsteps=100, integration_method='rk4', \n",
    "                    gradient=True, mode='gamma', addnoise=True,\n",
    "                    estimatenoise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max(lines, pad=.5, rangefactor=3):\n",
    "    if False:\n",
    "        lrange = max(.1, np.nanmax(lines[2]) - np.nanmin(lines[1]))\n",
    "        # clip range at rangefactor*maximum range\n",
    "        max_range = rangefactor * max(.1, np.nanmax(lines[0]) - np.nanmin(lines[0]))\n",
    "        lrange = min(lrange, max_range)\n",
    "        ymin = max(0., np.nanmin(lines[0]) - pad*lrange)\n",
    "        ymax = np.nanmax(lines[0]) + pad*lrange\n",
    "    else:\n",
    "        lrange = max(.1, np.nanmax(lines[0]) - np.nanmin(lines[0]))\n",
    "        ymin = max(0., np.nanmin(lines[0]) - pad*lrange)\n",
    "        ymax = np.nanmax(lines[0]) + pad*lrange\n",
    "    return (ymin, ymax)\n",
    "\n",
    "def plot_ukf(data, color1='#1f77b4', color2='#ff7f0e'):\n",
    "    f_options = []\n",
    "    for o in list(data.data_vars):\n",
    "        if not o.endswith('_err'):\n",
    "            f_options.append(o)\n",
    "    \n",
    "    feature_x = widgets.Dropdown(description='Feature 1:')\n",
    "    feature_y = widgets.Dropdown(description='Feature 2:')\n",
    "    feature_x.options = f_options\n",
    "    feature_y.options = f_options\n",
    "    feature1 = feature_x.options[0]\n",
    "    feature2 = feature_y.options[-1]\n",
    "    feature_y.value = feature2\n",
    "\n",
    "    traces = {}\n",
    "    for o in f_options:\n",
    "        if o+'_err' in list(data.data_vars):\n",
    "            # ignore warnings due to NaNs\n",
    "            with np.errstate(invalid='ignore'):\n",
    "                ymean = data[o].values\n",
    "                ymean = np.where(ymean < 0., 0., ymean)\n",
    "                yerr = data[o+'_err'].values\n",
    "                ymin = ymean - 3*yerr\n",
    "                ymin = np.where(ymin < 0., 0., ymin)\n",
    "                ymax = ymean + 3*yerr\n",
    "                traces[o] = [ymean, ymin, ymax]\n",
    "        else:\n",
    "            ymean = data[o].values\n",
    "            with np.errstate(invalid='ignore'):\n",
    "                ymean = np.where(ymean < 0., 0., ymean)\n",
    "            traces[o] = [ymean]\n",
    "            \n",
    "    xs = DateScale()\n",
    "    try:\n",
    "        dates = data['dates'].values\n",
    "    except KeyError:\n",
    "        dates = data['index'].values\n",
    "    y1 = traces[feature1]\n",
    "    y2 = traces[feature2]\n",
    "    y1min, y1max = get_min_max(y1)\n",
    "    y2min, y2max = get_min_max(y2)\n",
    "\n",
    "    ys = LinearScale(min=y1min, max=y1max)\n",
    "    panzoom = PanZoom(scales={'x': [xs], 'y': [ys]})\n",
    "    x_axis = Axis(scale=xs, label='Date')\n",
    "    y_axis_left = Axis(scale=ys, orientation='vertical', label=feature1,\n",
    "                       label_color=color1)\n",
    "    line_1 = Lines(x=dates, y=y1, scales={'x':xs, 'y':ys}, colors=[color1], fill='between', fill_opacities=[0, .5, .5])\n",
    "\n",
    "    ys1 = LinearScale(min=y2min, max=y2max)\n",
    "    y_axis_right = Axis(scale=ys1, orientation='vertical', label=feature2, side='right', grid_lines='none',\n",
    "                        label_color=color2)\n",
    "    line_2 = Lines(x=dates, y=y2, scales={'x':xs, 'y':ys1}, colors=[color2], fill='between', \n",
    "                   fill_opacities=[0, .5, .5], line_style='dashed')\n",
    "\n",
    "\n",
    "    fig = Figure(marks=[line_1, line_2], axes=[x_axis, y_axis_left, y_axis_right])\n",
    "    tb = Toolbar(figure=fig)\n",
    "\n",
    "    def update_plot(a):\n",
    "        y1 = traces[feature_x.value]\n",
    "        y2 = traces[feature_y.value]\n",
    "        y1min, y1max = get_min_max(y1)\n",
    "        y2min, y2max = get_min_max(y2)\n",
    "        ys.min = y1min\n",
    "        ys.max = y1max\n",
    "        ys1.min = y2min\n",
    "        ys1.max = y2max\n",
    "        basis1 = feature_x.value.split('_')[0]\n",
    "        basis2 = feature_y.value.split('_')[0]\n",
    "        if basis1 == basis2:\n",
    "            ys1.min = ys.min\n",
    "            ys1.max = ys.max\n",
    "        line_1.y = y1\n",
    "        line_2.y = y2\n",
    "        y_axis_left.label = feature_x.value\n",
    "        y_axis_right.label = feature_y.value\n",
    "\n",
    "    feature_x.observe(update_plot, 'value')\n",
    "    feature_y.observe(update_plot, 'value')\n",
    "\n",
    "    return VBox([HBox([feature_x, feature_y]), VBox([fig, tb])])\n",
    "\n",
    "plot_ukf(xds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uks = UnscentedKalmanSmoother(data=xds.to_dataframe())\n",
    "Q = np.eye(9)*[1e-3, 1e-3, 1e-3, 1e-10, 1e1, 1e1, 1e3, 1e4, 1e4]*uks.dt*uks.dt\n",
    "(T, M, X, Mi, Mo, qi) = uks.data.iloc[0][['T', 'M', 'X', 'Mi', 'Mo', 'qi']]\n",
    "dqi = 1e-1\n",
    "dMi = 1e-1\n",
    "dMo = 1e-1\n",
    "P0 = np.eye(9)*1e3\n",
    "X0 = [T, M, X, qi*0.0864, Mi, Mo, dqi, dMi, dMo]\n",
    "log_lh = uks(Q, X0, P0, test=True)\n",
    "print(log_lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ukf(uks.data.to_xarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from nsampling import NestedSampling, Uniform, Normal\n",
    "\n",
    "    T_Q = Uniform('T_Q', 1e-5, 1e-1)\n",
    "    M_Q = Uniform('M_Q', 1e-5, 1e-1)\n",
    "    X_Q = Uniform('X_Q', 1e-5, 1e-1)\n",
    "    qi_Q = Uniform('qi_Q', 1e-8, 1.)\n",
    "    Mi_Q = Uniform('Mi_Q', 1e-8, 1.)\n",
    "    Mo_Q = Uniform('Mo_Q', 1e-8, 1.)\n",
    "    dqi_Q = Uniform('dqi_Q',1e-1, 1e6)\n",
    "\n",
    "    ns = NestedSampling()\n",
    "    rs = ns.explore([T_Q, M_Q, X_Q, qi_Q, Mi_Q, Mo_Q, dqi_Q], 10, 300, likelihood=_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    [T_Q, M_Q, X_Q, qi_Q, Mi_Q, Mo_Q, dqi_Q] = rs.get_samples()[-1].get_value()\n",
    "    [T_Q, M_Q, X_Q, qi_Q, Mi_Q, Mo_Q, dqi_Q] = rs.getexpt()\n",
    "    dt = (df.index[1] - df.index[0])/pd.Timedelta('1D')\n",
    "    Q = np.eye(7)*[T_Q, M_Q, X_Q, qi_Q, Mi_Q, Mo_Q, dqi_Q]*dt*dt\n",
    "    xs, ps, Xs, Ps, log_lh = smooth(df, Q)\n",
    "    log_lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    maxlog = 1e-30\n",
    "    lhs = []\n",
    "    zs = []\n",
    "    for s in rs.get_samples():\n",
    "        lh = s.get_logL()\n",
    "        lhs.append(lh)\n",
    "        zs.append(s.get_logZ())\n",
    "        if lh>maxlog:\n",
    "            maxlog = lh\n",
    "            vals = s.get_value()\n",
    "\n",
    "    [T_Q, M_Q, X_Q, qi_Q, Mi_Q, Mo_Q, dqi_Q] = vals\n",
    "    Q = np.eye(7)*[T_Q, M_Q, X_Q, qi_Q, Mi_Q, Mo_Q, dqi_Q]*dt*dt\n",
    "    xs, ps, Xs, Ps, log_lh = smooth(df, Q)\n",
    "    plt.plot(zs)\n",
    "    plt.plot(lhs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clemb.data import LakeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = LakeData()\n",
    "df_rd = ld.get_data_fits('2018-11-01', '2019-09-11', smoothing='dv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T0, M0, C0 = df_rd.iloc[0][['T', 'M', 'X']].values\n",
    "Mi0 = 10.\n",
    "Mo0 = 10.\n",
    "qi0 = 200.\n",
    "dqi0 = 1e-1\n",
    "dMi0 = 1e-1\n",
    "dMo0 = 1e-1\n",
    "dt = (df_rd.index[1] - df_rd.index[0])/pd.Timedelta('1D')\n",
    "Q = np.eye(9)*[1e-2, 1e2, 1e-3, 1e-10, 1, 1, 1, 1e2, 1]*dt*dt\n",
    "X0 = [T0, M0, C0, qi0*0.0864, Mi0, Mo0, dqi0, dMi0, dMo0]\n",
    "P0 = np.eye(9)*[0.1*T0, 0.1*M0, 0.5*C0, 100*0.0864, 1e2, 1e2, 1., 1., 1.]\n",
    "uks1 = UnscentedKalmanSmoother(data=df_rd)\n",
    "log_lh = uks1(Q, X0, P0)\n",
    "print(log_lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "rs = xr.open_dataset('../../../tests/data/forward_2019-01-01_2019-08-26.nc')\n",
    "rs = rs.reindex(dict(dates=df_rd.index))\n",
    "q_ns = rs['exp'].loc[:,'q_in']\n",
    "q_ns_err = rs['var'].loc[:, 'q_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uks1.data['qi_ns'] = q_ns.data\n",
    "uks1.data['qi_ns_err'] = np.sqrt(q_ns_err.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ukf(uks1.data.to_xarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from nsampling import NestedSampling, Uniform, Normal\n",
    "    \n",
    "    def likelihood(var, sid, data):\n",
    "        dt = (data.index[1] - data.index[0])/pd.Timedelta('1D')\n",
    "        T_Q = var[0]\n",
    "        M_Q = var[1]\n",
    "        X_Q = var[2]\n",
    "        qi_Q = var[3]\n",
    "        Mi_Q = var[4]\n",
    "        Mo_Q = var[5]\n",
    "        dqi_Q = var[6]\n",
    "        dMi_Q = var[7]\n",
    "        dMo_Q = var[8]\n",
    "        Q = np.eye(9)*[T_Q, M_Q, X_Q, qi_Q, \n",
    "                       Mi_Q, Mo_Q, dqi_Q,\n",
    "                       dMi_Q, dMo_Q]*dt*dt\n",
    "        T0, M0, X0 = data.iloc[0][['T', 'M', 'X']]\n",
    "        Mi0 = 10.\n",
    "        Mo0 = 10.\n",
    "        dqi = 1e-1\n",
    "        qi0 = 100.\n",
    "        dqi0 = 1e-1\n",
    "        dMi0 = 1e-1\n",
    "        dMo0 = 1e-1\n",
    "        X0 = [T0, M0, X0, qi0*0.0864, Mi0, Mo0, dqi0, dMi0, dMo0]\n",
    "        try:\n",
    "            xs, ps, Xs, Ps, log_lh = uks(data, Q, X0)\n",
    "        except:\n",
    "            return 1e-10\n",
    "        return log_lh\n",
    "\n",
    "    _lh = partial(likelihood, data=df_rd)\n",
    "   \n",
    "\n",
    "    T_Q = Uniform('T_Q', 1e-4, 1e-1)\n",
    "    M_Q = Uniform('M_Q', 1e-4, 1e-1)\n",
    "    X_Q = Uniform('X_Q', 1e-4, 1e-1)\n",
    "    qi_Q = Uniform('qi_Q', 1e-8, 1.)\n",
    "    Mi_Q = Uniform('Mi_Q', 1e-3, 1e2)\n",
    "    Mo_Q = Uniform('Mo_Q', 1e-3, 1e2)\n",
    "    dqi_Q = Uniform('dqi_Q',1., 1e2)\n",
    "    dMi_Q = Uniform('dMi_Q', 1., 1e2)\n",
    "    dMo_Q = Uniform('dMo_Q', 1., 1e2)\n",
    "    ns_vars = [T_Q, M_Q, X_Q, qi_Q, Mi_Q,\n",
    "               Mo_Q, dqi_Q, dMi_Q, dMo_Q]\n",
    "    ns = NestedSampling()\n",
    "    rs_ns = ns.explore(ns_vars, 10, 300, likelihood=_lh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pumahu",
   "language": "python",
   "name": "pumahu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
