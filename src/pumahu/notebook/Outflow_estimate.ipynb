{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import pymc3 as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC for measured outflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://fits.geonet.org.nz/observation?siteID={}&typeID=z\"\n",
    "names = ['h', 'h_err']\n",
    "ldf = pd.read_csv(url.format('RU001'),\n",
    "                  index_col=0, names=names, skiprows=1,\n",
    "                  parse_dates=True)\n",
    "ldf1 = pd.read_csv(url.format('RU001A'),\n",
    "                   index_col=0, names=names, skiprows=1,\n",
    "                   parse_dates=True)\n",
    "ldf = ldf.combine_first(ldf1)\n",
    "ldf.loc[ldf.index < '1997-01-01', 'h'] = 2530. + \\\n",
    "    ldf.loc[ldf.index < '1997-01-01', 'h']\n",
    "ldf.loc[(ldf.index > '1997-01-01') & (ldf.index < '2012-12-31'),\n",
    "        'h'] = 2529.5 + \\\n",
    "    (ldf.loc[(ldf.index > '1997-01-01') &\n",
    "             (ldf.index < '2012-12-31'), 'h'] - 1.3)\n",
    "ldf.loc[ldf.index > '2016-01-01', 'h'] = 2529.35 + \\\n",
    "    (ldf.loc[ldf.index > '2016-01-01', 'h'] - 2.0)\n",
    "\n",
    "df = df_resample(ldf)\n",
    "df = df.loc[df.index >= '2016-03-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "of = np.array([['2019-02-26', 70.],\n",
    "               ['2018-06-10',200.],\n",
    "               ['2017-12-12', 86.],\n",
    "               ['2015-04-24', 8.9],\n",
    "               ['2012-01-25',23.],\n",
    "               ['2011-12-09',79.5],\n",
    "               ['2010-03-04', 86.],\n",
    "               ['2010-01-29', 175.]])\n",
    "dates = pd.DatetimeIndex(of[:,0])\n",
    "vals = of[:,1].astype(float)\n",
    "ofs = pd.Series(vals, index=dates)\n",
    "df['of'] = ofs\n",
    "df['of_err'] = pd.Series(vals*0.3, index=dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from field observations we assume that there is no \n",
    "# outflow below 1.9 m which is 10 cm below the \n",
    "# assumed reference level\n",
    "H_0 = 2529.25 \n",
    "\n",
    "# Set the outflow below H0 to 0.\n",
    "df['of'].loc[df['h'] < H_0] = 0.0\n",
    "\n",
    "# for lake levels below 1.9 m assign an linearly increasing error\n",
    "# to the outflow\n",
    "h_tmp = df['h'].loc[df['h'] < H_0]\n",
    "h_min = h_tmp.min()\n",
    "df['of_err'].loc[df['h'] < H_0] = 25*(h_tmp - h_min)/(H_0 - h_min)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "of = df['of'].values\n",
    "of_err = df['of_err'].values\n",
    "h = df['h'].values\n",
    "offset = h.min()\n",
    "h -= h.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import theano\n",
    "of_model = pm.Model()\n",
    "idx = h.argsort()\n",
    "hx = h[idx]\n",
    "ofy = of[idx]\n",
    "ofe = of_err[idx]\n",
    "ofe[0] = 1.\n",
    "x_shared = theano.shared(hx)\n",
    "y_shared = theano.shared(ofy)\n",
    "e_shared = theano.shared(ofe)\n",
    "with of_model:\n",
    "    a = pm.Uniform('a',1.e-6, 1e1)\n",
    "    b = pm.Uniform('b', 1.1, 1e3)\n",
    "    c = pm.Uniform('c', 1.1, 1e3)\n",
    "    g = a*np.exp(b*hx + c*hx*hx)\n",
    "    sigma = pm.Normal('sigma', mu=ofe, sd=20, shape=(ofe.size))\n",
    "    obs = pm.Normal('obs', mu=g, sd=sigma, observed=ofy)\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(draws=40000, tune=1000, chains=4, step=step)\n",
    "\n",
    "with open('outflow_model.pkl', 'wb') as buff:\n",
    "    pickle.dump({'model': of_model, 'trace': trace}, buff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pm.traceplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc = pm.sample_ppc(trace, samples=1000, model=of_model)\n",
    "mn_of = ppc['obs'].mean(axis=0)\n",
    "std_of = ppc['obs'].std(axis=0)\n",
    "plt.fill_between(hx, mn_of+std_of, mn_of-std_of, alpha=0.5)\n",
    "plt.plot(hx, mn_of, 'r--')\n",
    "plt.plot(hx, ofy, 'k+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def predict(x, xorig, trace, samples):\n",
    "    len_trace = len(trace)\n",
    "    y_predict = np.zeros((samples, x.size))\n",
    "    try:\n",
    "        nchain = trace.nchains\n",
    "    except AttributeError:\n",
    "        nchain = 1\n",
    "    indices = np.random.randint(0, nchain * len_trace, samples)\n",
    "    cnt = 0\n",
    "    for idx in indices:\n",
    "        if nchain > 1:\n",
    "            chain_idx, point_idx = np.divmod(idx, len_trace)\n",
    "            param = trace._straces[chain_idx].point(point_idx)\n",
    "        else:\n",
    "            param = trace[idx]\n",
    "        a = param['a']\n",
    "        b = param['b']\n",
    "        c = param['c']\n",
    "        sigma = param['sigma']\n",
    "        f = interp1d(xorig, sigma, fill_value='extrapolate')\n",
    "        n_sigma = f(x)\n",
    "        n_sigma = np.where(n_sigma > 0, n_sigma, 0.001)\n",
    "        y_predict[cnt] = np.random.normal(loc=a*np.exp(b*x + c*x*x),\n",
    "                                          scale=n_sigma)\n",
    "        cnt += 1\n",
    "    return y_predict\n",
    "xp = np.linspace(0, .7, 1000)\n",
    "yp = predict(xp, hx, trace, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_mean = yp.mean(axis=0)\n",
    "yp_std = yp.std(axis=0)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.fill_between(xp+offset, yp_mean+3*yp_std, yp_mean-3*yp_std, color='blue', alpha=0.5)\n",
    "ax.plot(xp+offset, yp_mean, 'b--')\n",
    "ax.plot(hx+offset, ofy, 'k')\n",
    "yp_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_min = np.where((yp_mean - 3*yp_std) > 0., (yp_mean - 3*yp_std)*0.0864, 0.)\n",
    "o_max = np.where((yp_mean + 3*yp_std)*0.0864 < 100., (yp_mean + 3*yp_std)*0.0864, 100.)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.fill_between(xp+offset, o_min, o_max, color='blue', alpha=0.5)\n",
    "np.savez('outflow_prior.npz', z=xp+offset, o_min=o_min, o_max=o_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('outflow_prior.npz')\n",
    "a['z']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
