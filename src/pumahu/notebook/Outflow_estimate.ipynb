{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from pumahu import get_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC for measured outflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_resample(df):\n",
    "    \"\"\"\n",
    "    Resample dataframe to daily sample rate.\n",
    "    \"\"\"\n",
    "    # First upsample to 15 min intervals combined with a\n",
    "    # linear interpolation\n",
    "    ndates = pd.date_range(start=df.index.date[0], end=df.index.date[-1],\n",
    "                           freq='15T')\n",
    "    ndf = df.reindex(ndates, method='nearest',\n",
    "                     tolerance=np.timedelta64(15, 'm')).interpolate()\n",
    "    # Then downsample to 1 day intervals assigning the new values\n",
    "    # to mid day\n",
    "    ndf = ndf.resample('1D', label='left').mean()\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://fits.geonet.org.nz/observation?siteID={}&typeID=z\"\n",
    "names = ['h', 'h_err']\n",
    "ldf = pd.read_csv(url.format('RU001'),\n",
    "                  index_col=0, names=names, skiprows=1,\n",
    "                  parse_dates=True)\n",
    "ldf1 = pd.read_csv(url.format('RU001A'),\n",
    "                   index_col=0, names=names, skiprows=1,\n",
    "                   parse_dates=True)\n",
    "ldf = ldf.combine_first(ldf1)\n",
    "ldf = ldf.tz_localize(None)\n",
    "\n",
    "df = df_resample(ldf)\n",
    "df = df.loc[df.index >= '2016-03-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo = pd.read_csv(get_data('data/outflow.csv'), parse_dates=True, index_col=0,\n",
    "                 names=['Date', 'of', 'of_err'], skiprows=1)\n",
    "dfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['of'] = dfo['of']\n",
    "df['of_err'] = dfo['of_err']\n",
    "df[df.of>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['h', 'of', 'of_err']][df.of>0].values\n",
    "min_level = 0.95*data.min(axis=0)[0]\n",
    "lowest_level = 1.\n",
    "zerolevels = []\n",
    "for l in np.linspace(lowest_level, min_level, 3):\n",
    "    l_error = 30*(l - lowest_level)/(min_level - lowest_level)\n",
    "    zerolevels.append([l, 0.0, l_error])\n",
    "zerolevels = np.array(zerolevels)\n",
    "data = np.vstack((zerolevels, data))\n",
    "x = data[:, 0]\n",
    "y = data[:, 1]\n",
    "yerr = data[:, 2]\n",
    "idx = x.argsort()\n",
    "x = x[idx]\n",
    "y = y[idx]\n",
    "yerr = yerr[idx]\n",
    "yerr[0] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nsampling import NestedSampling, Uniform, Normal\n",
    "from functools import partial\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def f(b, c, k, x):\n",
    "    a = 250.\n",
    "    return a / (1+np.exp(-k*(x*c -b)))\n",
    "\n",
    "def likelihood(vals, sid, x, y, sigma):\n",
    "    a = 250.\n",
    "    b = vals[0]\n",
    "    c = vals[1]\n",
    "    k = vals[2]\n",
    "    new_data = f(b, c, k, x)\n",
    "    cov = np.eye(sigma.size)*sigma*sigma\n",
    "    return multivariate_normal.logpdf(new_data, mean=y, cov=cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Uniform('b', 1., 1e2)\n",
    "c = Uniform('c', 1., 1e2)\n",
    "k = Uniform('k', 1e-6, 1.)\n",
    "ns = NestedSampling(seed=42)\n",
    "lh = partial(likelihood, x=x, y=y, sigma=yerr)\n",
    "rs = ns.explore(vars=[b, c, k], initial_samples=100,\n",
    "                maximum_steps=10000, \n",
    "                likelihood=lh, tolZ=-1, tolH=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from matplotlib.colors import Normalize\n",
    "cmap = cm.ScalarMappable(norm=Normalize(vmin=-300, vmax=-150), cmap='RdBu_r')\n",
    "logLs = []\n",
    "smp = rs.get_samples()\n",
    "smp1 = rs.resample_posterior(100)\n",
    "bs = []\n",
    "cs = []\n",
    "ks = []\n",
    "wt = []\n",
    "h = []\n",
    "z = []\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(18,5))\n",
    "for _s in smp:\n",
    "    cl = cmap.to_rgba(_s.get_logL())\n",
    "    logLs.append(_s.get_logL())\n",
    "    b, c, k = _s.get_value()\n",
    "    bs.append(b)\n",
    "    cs.append(c)\n",
    "    ks.append(k)\n",
    "    wt.append(_s.get_logWt())\n",
    "    z.append(_s.get_logZ())\n",
    "    h.append(_s.get_H())\n",
    "    axs[0].plot(b,k,ms=5,color=cl,marker='o',alpha=0.3)\n",
    "    \n",
    "for _s in smp1:\n",
    "    b, c, k = _s.get_value()\n",
    "    axs[0].plot(b,k,ms=5,color='k',marker='+')\n",
    "cmap.set_array(logLs)\n",
    "cb = plt.colorbar(cmap, ax=axs[0])\n",
    "cb.set_label('Log-Likelihood')\n",
    "axs[1].plot(z)\n",
    "axs[1].set_ylabel('Log Evidence')\n",
    "axs[1].set_xlabel('Sample #')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(smp, x, xorig, sigma, error=True):\n",
    "    y_predict = np.zeros((len(smp), x.size))\n",
    "    cnt = 0\n",
    "    for _s in smp:\n",
    "        b, c, k = _s.get_value()\n",
    "        a = 250. #param['a']\n",
    "        f = interp1d(xorig, sigma, fill_value='extrapolate')\n",
    "        n_sigma = f(x)\n",
    "        n_sigma = np.where(n_sigma > 0, n_sigma, 0.001)\n",
    "        if error:\n",
    "            y_predict[cnt] = np.random.normal(loc=a / (1+np.exp(-k*(x*c -b))),\n",
    "                                              scale=n_sigma)\n",
    "        else:\n",
    "            y_predict[cnt] = a / (1+np.exp(-k*(x*c -b)))\n",
    "        cnt += 1\n",
    "    return y_predict\n",
    "xp = np.linspace(1.0, 2.3, 1000)\n",
    "yp = predict(smp1, xp, x, yerr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstd = 2\n",
    "offset = 2527.35 \n",
    "yp_mean = yp.mean(axis=0)\n",
    "yp_std = yp.std(axis=0)\n",
    "o_min = np.where((yp_mean - nstd*yp_std) > 0., (yp_mean - nstd*yp_std), 0.)\n",
    "o_max = yp_mean + nstd*yp_std\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.fill_between(xp, o_min*0.0864, o_max*0.0864, color='blue', alpha=0.1)\n",
    "ax.errorbar(x, y*0.0864, yerr=yerr*0.0864, marker='o', elinewidth=1, linewidth=0)\n",
    "ax.plot(xp, yp_mean*0.0864, 'k-')\n",
    "if False:\n",
    "    np.savez(get_data('data/outflow_prior.npz'), z=xp+offset, o_min=o_min*0.0864, o_max=o_max*0.0864,\n",
    "             o_mean=yp_mean*0.0864)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pumahu",
   "language": "python",
   "name": "pumahu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
